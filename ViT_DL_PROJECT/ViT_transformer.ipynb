{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1305,"status":"ok","timestamp":1684341563849,"user":{"displayName":"Ken He","userId":"08360698100872291870"},"user_tz":240},"id":"P1VoD282o4F8","outputId":"8c4977f1-0f01-4e47-cccd-0756be6d78be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":64}],"source":["import torch.nn as nn\n","from torch.optim import Adam\n","import torch\n","from torch.utils.data import DataLoader, SubsetRandomSampler, random_split\n","from torchvision import datasets, transforms, models\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","import numpy as np\n","import os\n","import random\n","import warnings\n","import tqdm.notebook as tqdm\n","import matplotlib.pyplot as plt\n","import torchvision\n","from google.colab import drive\n","import copy\n","import pandas as pd\n","\n","\n","# looked at pytorch documentation\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","drive.mount(\"/content/drive\")\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibzpV6zJ1r0d"},"outputs":[],"source":["# Hyperparameters\n","learning_rate = 0.0001\n","batch_size = 30\n","num_epochs = 50\n","weight_decay = 0.05\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ML9xsu8vp9-f"},"outputs":[],"source":["# Load Data\n","data_path = '/content/drive/MyDrive/DL_FP'\n","path = '/content/drive/MyDrive/DL_FP_ViT'\n","\n","\n","# Load weights\n","weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNQE_3LS12Xc"},"outputs":[],"source":["# Similarly for testing, we just normalize it without any augmentation\n","transforms_ = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2etjQRC51Jmd"},"outputs":[],"source":["percent_data_used = 1\n","\n","# Load dataset\n","transform = transforms.Compose([transforms.ToTensor()])\n","full_dataset = datasets.ImageFolder(root=data_path + '/spectrograms/',transform=transform)\n","\n","# Determine the number of samples to take for 10%\n","num_samples = len(full_dataset)\n","num_subset = int(percent_data_used*num_samples)\n","\n","# Perform the split\n","subset, _ = random_split(full_dataset, [num_subset, num_samples - num_subset])\n","\n","# Select the dataset to use\n","\n","dataset = full_dataset\n","\n","# Define the indices\n","indices = list(range(len(dataset)))\n","np.random.shuffle(indices)\n","\n","# Split the data into training (60%), validation (20%) and testing (20%)\n","train_split = int(np.floor(0.6 * len(dataset)))\n","valid_split = int(np.floor(0.8 * len(dataset)))\n","\n","train_indices = indices[:train_split]\n","valid_indices = indices[train_split:valid_split]\n","test_indices = indices[valid_split:]\n","\n","# Create Samplers\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(valid_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","# Create DataLoaders\n","dataloaders = {\n","    'train': DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4),\n","    'valid': DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4),\n","    'test': DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=4)\n","}\n","\n","# Apply different transforms to the data\n","dataloaders['train'].dataset.transform = transforms_\n","dataloaders['valid'].dataset.transform = transforms_\n","dataloaders['test'].dataset.transform = transforms_\n","\n","# Create DataLoaders\n","dataset_sizes = {x: len(dataloaders[x].sampler) for x in dataloaders.keys()}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaniMH_k5ZAW"},"outputs":[],"source":["train_loader = dataloaders['train']\n","test_loader = dataloaders['test']\n","vlid_loader = dataloaders['valid']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjIbCtYGyhFD"},"outputs":[],"source":["# construct the model\n","\n","preprocess = weights.transforms()\n","\n","model = torchvision.models.vit_b_16(weights=weights)\n","\n","# freeze all the parameters\n","\n","for param in model.parameters():\n","  param.requires_grad = False\n","\n","# Unfreeze the last swin transformer block\n","for param in model.encoder.layers.encoder_layer_11.parameters():\n","  param.requires_grad = True\n","\n","for param in model.encoder.ln.parameters():\n","  param.requires_grad = True\n","\n","# change the last fc layer\n","num_inft = model.heads.head.in_features\n","model.heads.head = nn.Linear(num_inft, 8)\n","model = model.to(device)\n"]},{"cell_type":"code","source":["new_p = 0.85\n","\n","model.encoder.layers.encoder_layer_11.dropout.p = new_p\n","model.encoder.layers.encoder_layer_11.mlp[2].p = new_p\n","model.encoder.layers.encoder_layer_11.mlp[4].p = new_p"],"metadata":{"id":"UL2Yiqk7lWrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fozz0ddSDPBe"},"outputs":[],"source":["def get_loss(model: nn.Module, test_loader: torch.utils.data.DataLoader):\n","\n","  total_loss = 0\n","  n_batches = 0\n","  correct = 0\n","  total = 0\n","\n","  # since we're not training, we don't need to calculate the gradients for our outputs\n","  with torch.no_grad():\n","      for data in tqdm.tqdm(test_loader, colour='green', desc='test', leave=False):\n","          images, labels = data\n","          images = images.cuda()\n","          labels = labels.cuda()\n","          outputs = model(images)\n","          total_loss += criterion(outputs, labels).item()\n","          \n","          n_batches += 1\n","          total += len(labels)\n","           \n","          pred_labels = outputs.argmax(dim=1)\n","          correct += (pred_labels == labels).sum().item()\n","           \n","  return (total_loss / n_batches), (correct / total)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvqIWgf122yY"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","def percision_recall_F1(model, dataloader, num_classes):\n","\n","    total_labels = []\n","    total_predictions = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            predicted = outputs.argmax(dim=1)\n","            total_labels.extend(labels.cpu().numpy())\n","            total_predictions.extend(predicted.cpu().numpy())\n","            \n","    labels = total_labels\n","    predicted = total_predictions\n","\n","    precision = precision_score(labels, predicted, average=\"macro\")\n","    recall = recall_score(labels, predicted, average=\"macro\")\n","    f1 = f1_score(labels, predicted, average=\"macro\")\n","\n","    print(f'Precision: {precision} \\n Recall: {recall} \\n F1: {f1}')\n","\n","    return precision, recall"]},{"cell_type":"code","source":["\n","\n","checkpoint = \"\"\n","prev_epoch = 0\n","\n","if checkpoint != \"\":\n","  checkpoint = torch.load(path + f\"/checkpoints/checkpoint_{prev_epoch}.pth\" )\n","  model.load_state_dict(checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","  epoch = checkpoint['epoch']\n","  loss = checkpoint['loss']"],"metadata":{"id":"EwPBVE1HyVer"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Tuple\n","import tqdm.notebook as tqdm\n","import torch.optim as optim\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"],"metadata":{"id":"AvydUHGRy6ri"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlY0C-KG5fh-","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0b8ff3500421463fb9480615e0717095","06ea1e665381422a97e8914dc2290312","f4c69180c7e743468a41cede4942e7ac","f901e01829d74bc398367df43340ff9c","af6f87953a194e61b936ad1108a12839","b0a48b55e96e46a58b34eed48475a25b","ea6e77fa7b484249a3bebd509ca25f77","dc1ca872bb0e4450b6c7ef6e94a3aa2c","806799e901124367acb455d9ecdedf88","0853d525cb1840c38b30e186230f55dd","e0596dabe804494ca435339bb7a6046a"]},"outputId":"5004afa7-93f6-46c6-bcea-d18c814099aa"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b8ff3500421463fb9480615e0717095"}},"metadata":{}}],"source":["log_freq = 100\n","checkpoint_interval = 20\n","\n","train_losses = []\n","valid_losses = []\n","train_accs = []\n","valid_accs = []\n","total_steps = 0\n","\n","best_acc = 0.0\n","best_loss = 100\n","best_model_wts = copy.deepcopy(model.state_dict())\n","\n","for epoch in tqdm.trange(num_epochs, desc='Epoch', colour='pink'):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    running_loss_steps = 0\n","    num_train_predictions_correct = 0\n","    num_train_predictions_total = 0\n","\n","    for i, data in enumerate(tqdm.tqdm(train_loader, desc='batch', colour='blue', leave=False), 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        # compute train accuracy\n","        pred_labels = outputs.argmax(dim=1)\n","        num_train_predictions_correct += (pred_labels == labels).sum().item()\n","        num_train_predictions_total += len(pred_labels)\n","\n","        # # print statistics\n","        total_steps += 1\n","        running_loss += loss.item()\n","        running_loss_steps += 1\n","\n","\n","    valid_loss, valid_acc = get_loss(model, vlid_loader)\n","    avg_train_loss = running_loss / running_loss_steps\n","    avg_train_acc = (num_train_predictions_correct / num_train_predictions_total)\n","    print(f'[Step {total_steps}] train_loss: {avg_train_loss:.3f} || valid_loss = {valid_loss:.3f}')\n","    print(f'\\t\\t train_acc={avg_train_acc*100:.1f}% || valid_acc={valid_acc*100:.1f}%')\n","    # \n","    train_losses.append(avg_train_loss)\n","    valid_losses.append(valid_loss)\n","    train_accs.append(avg_train_acc)\n","    valid_accs.append(valid_acc)\n","    # \n","    num_train_predictions_correct = 0\n","    num_train_predictions_total = 0\n","    running_loss = 0.0\n","    running_loss_steps = 0\n","\n","    if valid_loss < best_loss:\n","      best_loss = valid_loss\n","      print(f\"model saved. loss:{valid_loss}\")\n","      torch.save(model.state_dict(), path + \"/best_model\")\n","\n","    if epoch % checkpoint_interval == 0:\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': loss,\n","            # You can include more stuff here...\n","        }, f'/content/drive/MyDrive/DL_FP_ViT/checkpoints/checkpoint_{epoch}.pth')\n","\n","\n","print('Finished Training')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDsggoG8sJdM"},"outputs":[],"source":["import pandas as pd\n","\n","performance = pd.DataFrame({\"train_losses\": train_losses, \"valid_losse\": valid_losses, \"train_accs\": train_accs, \"valid_accs\": valid_accs})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFO-MJv7t0HB"},"outputs":[],"source":["performance.to_csv(path + \"/performances_may_17_12pm.csv\")\n","# performance = pd.read_csv(path + \"/performances_may_17_12pm.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FA_dt3F5fkF"},"outputs":[],"source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/DL_FP_ViT/model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4R5xTSc-4RI-"},"outputs":[],"source":["percision_recall_F1(model, test_loader, 8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kueL-d4Cl8y"},"outputs":[],"source":["# Load training weight\n","\n","best_model_wts = torch.load(\"/content/drive/MyDrive/DL_FP_ViT/best_model\")\n","model.load_state_dict(best_model_wts)\n","get_loss(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Awg6r4AsUi5"},"outputs":[],"source":["def plot_data(train_accuracy, test_accuracy, train_loss, test_loss):\n","    epochs = range(1, len(train_accuracy) + 1)\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, train_accuracy, color='magenta', label='Train Accuracy', linestyle='-')\n","    plt.plot(epochs, test_accuracy, color='turquoise', label='Validation Accuracy', linestyle='-')\n","    plt.title('ViT Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, train_loss, color='magenta', label='Train Loss', linestyle='-')\n","    plt.plot(epochs, test_loss, color='turquoise', label='Validation Loss', linestyle='-')\n","    plt.title('ViT Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","plot_data(performance[\"train_accs\"], performance[\"valid_accs\"],performance[\"train_losses\"],performance[\"valid_losse\"])"]},{"cell_type":"code","source":["import seaborn as sns\n","\n","def plot_confusion_matrix(model, dataloader, num_classes):\n","\n","\n","    total_labels = []\n","    total_predictions = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            predicted = outputs.argmax(dim=1)\n","            total_labels.extend(labels.cpu().numpy())\n","            total_predictions.extend(predicted.cpu().numpy())\n","\n","            # for i in range(len(labels)):\n","            #     label = labels[i]\n","            #     correct_predictions[label] += (predicted[i] == label).item()\n","            #     total_predictions[label] += 1\n","\n","    # Compute the confusion matrix\n","    \n","\n","    genres = [\"Electronic\", \"Experimental\", \"Folk\", \"Hip-Hop\", \"Instrumental\", \"International\", \"Pop\", \"Rock\"]\n","\n","    cm = confusion_matrix(total_labels, total_predictions)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"cool\", xticklabels=genres, yticklabels=genres)\n","    plt.xticks(rotation=30)\n","\n","    plt.title(\"ViT_B_16 Confusion Matrix\")\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    plt.show()\n","\n","plot_confusion_matrix(model,test_loader, 8)\n","\n"],"metadata":{"id":"38GGkzyvdo_q"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b8ff3500421463fb9480615e0717095":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06ea1e665381422a97e8914dc2290312","IPY_MODEL_f4c69180c7e743468a41cede4942e7ac","IPY_MODEL_f901e01829d74bc398367df43340ff9c"],"layout":"IPY_MODEL_af6f87953a194e61b936ad1108a12839"}},"06ea1e665381422a97e8914dc2290312":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0a48b55e96e46a58b34eed48475a25b","placeholder":"​","style":"IPY_MODEL_ea6e77fa7b484249a3bebd509ca25f77","value":"Epoch:   8%"}},"f4c69180c7e743468a41cede4942e7ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc1ca872bb0e4450b6c7ef6e94a3aa2c","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_806799e901124367acb455d9ecdedf88","value":4}},"f901e01829d74bc398367df43340ff9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0853d525cb1840c38b30e186230f55dd","placeholder":"​","style":"IPY_MODEL_e0596dabe804494ca435339bb7a6046a","value":" 4/50 [06:01&lt;1:08:59, 89.99s/it]"}},"af6f87953a194e61b936ad1108a12839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0a48b55e96e46a58b34eed48475a25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea6e77fa7b484249a3bebd509ca25f77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc1ca872bb0e4450b6c7ef6e94a3aa2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"806799e901124367acb455d9ecdedf88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":"pink","description_width":""}},"0853d525cb1840c38b30e186230f55dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0596dabe804494ca435339bb7a6046a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}